{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:36:50.978107Z",
     "start_time": "2024-09-06T08:36:48.777747Z"
    }
   },
   "outputs": [],
   "source": [
    "from kan import KAN\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "import numpy as np\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b5654c3e5158125e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b069933a3f93db1f"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#读取数据\n",
    "# sequences_test = []\n",
    "# \n",
    "# # Open the text file in read mode\n",
    "# with open('/tmp/pycharm_project_763/data/testsets/AAP_test.txt', 'r') as file:\n",
    "#     lines = file.readlines()\n",
    "# \n",
    "#     # Iterate through the lines to extract protein sequences\n",
    "#     for line in lines:\n",
    "#         if not line.startswith('>'):\n",
    "#             # Strip any leading/trailing whitespace and add to the list\n",
    "#             sequences_test.append(line.strip())\n",
    "#             \n",
    "# y_test = []\n",
    "# \n",
    "# # Open the text file in read mode\n",
    "# with open('/tmp/pycharm_project_763/data/testsets/label_AAP_test.txt', 'r') as file:\n",
    "#     lines = file.readlines()\n",
    "# \n",
    "#     # Iterate through each line\n",
    "#     for line in lines:\n",
    "#         # Split the line by whitespace and check if it has two columns\n",
    "#         parts = line.strip().split()\n",
    "#         if len(parts) == 2:\n",
    "#             # The second part is the label\n",
    "#             y_test.append(int(parts[1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T01:48:55.805272Z",
     "start_time": "2024-08-24T01:48:55.794045Z"
    }
   },
   "id": "30dcb398b09989e3"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "#读取数据\n",
    "# sequences = []\n",
    "# \n",
    "# # Open the text file in read mode\n",
    "# with open('/tmp/pycharm_project_763/data/trainsets/AAP.txt', 'r') as file:\n",
    "#     lines = file.readlines()\n",
    "# \n",
    "#     # Iterate through the lines to extract protein sequences\n",
    "#     for line in lines:\n",
    "#         if not line.startswith('>'):\n",
    "#             # Strip any leading/trailing whitespace and add to the list\n",
    "#             sequences.append(line.strip())\n",
    "#             \n",
    "# y = []\n",
    "# \n",
    "# # Open the text file in read mode\n",
    "# with open('/tmp/pycharm_project_763/data/trainsets/label_AAP_1.txt', 'r') as file:\n",
    "#     lines = file.readlines()\n",
    "# \n",
    "#     # Iterate through each line\n",
    "#     for line in lines:\n",
    "#         # Split the line by whitespace and check if it has two columns\n",
    "#         parts = line.strip().split()\n",
    "#         if len(parts) == 2:\n",
    "#             # The second part is the label\n",
    "#             y.append(int(parts[1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T01:48:56.337326Z",
     "start_time": "2024-08-24T01:48:56.329085Z"
    }
   },
   "id": "7c6e4614c8633652"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(214, 56, 214, 56)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(sequences),len(sequences_test),len(y),len(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T01:48:57.212742Z",
     "start_time": "2024-08-24T01:48:57.200475Z"
    }
   },
   "id": "201857a68225608b"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "(951, 105)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_fasta(file_path):\n",
    "    protein_list=[]\n",
    "    label_list=[]\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                # 提取标签\n",
    "                label = line.split('|')[1]\n",
    "                label_list.append(int(label))\n",
    "            else:\n",
    "                # 提取蛋白质序列\n",
    "                protein_list.append(line)\n",
    "\n",
    "    return protein_list, label_list\n",
    "\n",
    "# 示例文件路径\n",
    "train_path = '/tmp/pycharm_project_763/raw/AVP.txt'\n",
    "test_path ='/tmp/pycharm_project_763/raw/AVPT.txt'\n",
    "\n",
    "sequences, y = read_fasta(train_path)\n",
    "sequences_test, y_test = read_fasta(test_path)\n",
    "len(sequences),len(sequences_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:44:10.833233Z",
     "start_time": "2024-09-06T08:44:10.827416Z"
    }
   },
   "id": "b7a975eecf9cf87e"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "(951, 167)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def maccs_feature():\n",
    "    maccs_list=[]\n",
    "    with open('/tmp/pycharm_project_763/raw/maccs_AVP.txt','r') as f:\n",
    "        for line in f:\n",
    "            maccs=list(map(int,line.strip().split()))\n",
    "            # print(maccs)\n",
    "            maccs_list.append(maccs)\n",
    "    return maccs_list\n",
    "maccs_train=maccs_feature()\n",
    "           \n",
    "len(maccs_train),len(maccs_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:44:24.113004Z",
     "start_time": "2024-09-06T08:44:24.082279Z"
    }
   },
   "id": "914c3d8d88af6eca"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "(105, 167)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def maccs_feature():\n",
    "    maccs_list=[]\n",
    "    with open('/tmp/pycharm_project_763/raw/maccs_AVPT.txt','r') as f:\n",
    "        for line in f:\n",
    "            maccs=list(map(int,line.strip().split()))\n",
    "            # print(maccs)\n",
    "            maccs_list.append(maccs)\n",
    "    return maccs_list\n",
    "maccs_test=maccs_feature()\n",
    "           \n",
    "len(maccs_test),len(maccs_test[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:44:24.743507Z",
     "start_time": "2024-09-06T08:44:24.727231Z"
    }
   },
   "id": "7b94dfd0435de3f4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def calculate_aac(protein_list):\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "\n",
    "    # 初始化存储结果的列表\n",
    "    aac_list = []\n",
    "\n",
    "    for protein_sequence in protein_list:\n",
    "        # 初始化AAC特征字典\n",
    "        aac = {aa: 0 for aa in amino_acids}\n",
    "\n",
    "        # 计算每种氨基酸在序列中的频率\n",
    "        for aa in protein_sequence:\n",
    "            if aa in aac:\n",
    "                aac[aa] += 1\n",
    "\n",
    "        # 将频率转换为比例\n",
    "        sequence_length = len(protein_sequence)\n",
    "        aac = [count / sequence_length for aa, count in aac.items()]\n",
    "\n",
    "        # 将结果添加到列表中\n",
    "        aac_list.append(aac)\n",
    "\n",
    "    return aac_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:36:59.389682Z",
     "start_time": "2024-09-06T08:36:59.389414Z"
    }
   },
   "id": "12bc6d47392e85b4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "aac_train = calculate_aac(sequences)\n",
    "aac_test = calculate_aac(sequences_test)\n",
    "# aac_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:37:00.200437Z",
     "start_time": "2024-09-06T08:37:00.198536Z"
    }
   },
   "id": "2739985cc1def56b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(951, 566)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAKH900113 = {\n",
    "    'A': 1.61, 'L': 1.37,\n",
    "    'R': 0.40, 'K': 0.62,\n",
    "    'N': 0.73, 'M': 1.59,\n",
    "    'D': 0.75, 'F': 1.24,\n",
    "    'C': 0.37, 'P': 0.67,\n",
    "    'Q': 0.61, 'S': 0.68,\n",
    "    'E': 1.50, 'T': 0.92,\n",
    "    'G': 3.12, 'W': 1.63,\n",
    "    'H': 0.46, 'Y': 0.67,\n",
    "    'I': 1.61, 'V': 1.30\n",
    "}\n",
    "KRIW710101={\n",
    "    'A': 4.60, 'L': 3.25,\n",
    "    'R': 6.50, 'K': 7.90,\n",
    "    'N': 5.90, 'M': 1.40,\n",
    "    'D': 5.70, 'F': 3.20,\n",
    "    'C': -1.00, 'P': 7.00,\n",
    "    'Q': 6.10, 'S': 5.25,\n",
    "    'E': 5.60, 'T': 4.80,\n",
    "    'G': 7.60, 'W': 4.00,\n",
    "    'H': 4.50, 'Y': 4.35,\n",
    "    'I': 2.60, 'V': 3.40\n",
    "}\n",
    "HUTJ700103={\n",
    "    'A': 154.33, 'L': 232.30,\n",
    "    'R': 341.01, 'K': 300.46,\n",
    "    'N': 207.90, 'M': 202.65,\n",
    "    'D': 194.91, 'F': 204.74,\n",
    "    'C': 219.79, 'P': 179.93,\n",
    "    'Q': 235.51, 'S': 174.06,\n",
    "    'E': 223.16, 'T': 205.80,\n",
    "    'G': 127.90, 'W': 237.01,\n",
    "    'H': 242.54, 'Y': 229.15,\n",
    "    'I': 233.21, 'V': 207.60\n",
    "}\n",
    "ZIMJ680103={\n",
    "    'A': 0.00, 'L': 0.13,\n",
    "    'R': 52.00, 'K': 49.50,\n",
    "    'N': 3.38, 'M': 1.43,\n",
    "    'D': 49.70, 'F': 0.35,\n",
    "    'C': 1.48, 'P': 1.58,\n",
    "    'Q': 3.53, 'S': 1.67,\n",
    "    'E': 49.90, 'T': 1.66,\n",
    "    'G': 0.00, 'W': 2.10,\n",
    "    'H': 51.60, 'Y': 1.61,\n",
    "    'I': 0.13, 'V': 0.13\n",
    "}\n",
    "TANS770104= {\n",
    "    'A': 1.194, 'L': 0.595,\n",
    "    'R': 0.795, 'K': 1.060,\n",
    "    'N': 0.659, 'M': 0.831,\n",
    "    'D': 1.056, 'F': 0.377,\n",
    "    'C': 0.678, 'P': 3.159,\n",
    "    'Q': 1.290, 'S': 1.444,\n",
    "    'E': 0.928, 'T': 1.172,\n",
    "    'G': 1.015, 'W': 0.452,\n",
    "    'H': 0.611, 'Y': 0.816,\n",
    "    'I': 0.603, 'V': 0.640\n",
    "}\n",
    "CEDJ970105={\n",
    "    'A': 8.3, 'L': 7.4,\n",
    "    'R': 8.7, 'K': 7.9,\n",
    "    'N': 3.7, 'M': 2.3,\n",
    "    'D': 4.7, 'F': 2.7,\n",
    "    'C': 1.6, 'P': 6.9,\n",
    "    'Q': 4.7, 'S': 8.8,\n",
    "    'E': 6.5, 'T': 5.1,\n",
    "    'G': 6.3, 'W': 0.7,\n",
    "    'H': 2.1, 'Y': 2.4,\n",
    "    'I': 3.7, 'V': 5.3\n",
    "}\n",
    "QIAN880127={\n",
    "    'A': -0.05, 'L': 0.04,\n",
    "    'R': 0.06, 'K': -0.42,\n",
    "    'N': 0.00, 'M': 0.25,\n",
    "    'D': 0.15, 'F': 0.09,\n",
    "    'C': 0.30, 'P': 0.31,\n",
    "    'Q': -0.08, 'S': -0.11,\n",
    "    'E': -0.02, 'T': -0.06,\n",
    "    'G': -0.14, 'W': 0.19,\n",
    "    'H': -0.07, 'Y': 0.33,\n",
    "    'I': 0.26, 'V': 0.04\n",
    "}\n",
    "LEVM760107={\n",
    "    'A': 0.025, 'L': 0.19,\n",
    "    'R': 0.20, 'K': 0.19,\n",
    "    'N': 0.10, 'M': 0.19,\n",
    "    'D': 0.10, 'F': 0.39,\n",
    "    'C': 0.10, 'P': 0.17,\n",
    "    'Q': 0.10, 'S': 0.025,\n",
    "    'E': 0.10, 'T': 0.10,\n",
    "    'G': 0.025, 'W': 0.56,\n",
    "    'H': 0.10, 'Y': 0.39,\n",
    "    'I': 0.19, 'V': 0.15\n",
    "}\n",
    "def autocorrelation(protein_list, lag, AAindex_list):\n",
    "    autocorrelation = []\n",
    "    for sequence in protein_list:\n",
    "        temp=[]\n",
    "        for property_values in AAindex_list:\n",
    "        # 将氨基酸序列转换为属性值序列\n",
    "        #     property_values = np.array([property_dict[aa] for aa in sequence])\n",
    "            property_values = [0 if value is None else value for value in property_values]\n",
    "            # 计算属性值的平均值\n",
    "            # print(property_values)\n",
    "            mean_value = np.mean(property_values)\n",
    "            # print(mean_value)\n",
    "            # 计算Moran自相关\n",
    "            n = len(sequence)\n",
    "            autocorr = np.sum((property_values[:-lag] - mean_value) * (property_values[lag:] - mean_value))\n",
    "            autocorr /= (n - lag)\n",
    "            temp.append(autocorr)\n",
    "            \n",
    "        autocorrelation.append(temp)\n",
    "    \n",
    "    return autocorrelation\n",
    "\n",
    "hydrophobicity = {\n",
    "    'A': 1.8, 'C': 2.5, 'D': -3.5, 'E': -3.5, 'F': 2.8, 'G': -0.4, 'H': -3.2, 'I': 4.5, \n",
    "    'K': -3.9, 'L': 3.8, 'M': 1.9, 'N': -3.5, 'P': -1.6, 'Q': -3.5, 'R': -4.5, 'S': -0.8,\n",
    "    'T': -0.7, 'V': 4.2, 'W': -0.9, 'Y': -1.3\n",
    "}\n",
    "\n",
    "lag = 1  # 步长\n",
    "import pandas as pd\n",
    "    # \"\"\"加载AAindex数据，假设第一列为描述，其余列为各个氨基酸的物理化学属性值。\"\"\"\n",
    "import csv\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = 'aaindex1.csv'\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Open the CSV file and read it\n",
    "with open(csv_file_path, mode='r', encoding='utf-8') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    \n",
    "    # Skip the first cell of the first row\n",
    "    for row in csv_reader:\n",
    "        # Append the row with the first cell removed to the data list\n",
    "        # data.append([float(value) for value in row[1:]])\n",
    "        data.append(row[1:])\n",
    "data=data[1:]\n",
    "# float_data = [[float(value) for value in row] for row in data]\n",
    "\n",
    "\n",
    "AAindex_data = [\n",
    "    [float(value) if value not in ['NA', ''] else None for value in row]\n",
    "    for row in data\n",
    "]\n",
    "\n",
    "# AAindex_list=[ NAKH900113, KRIW710101, HUTJ700103,ZIMJ680103,TANS770104,CEDJ970105, QIAN880127, LEVM760107]\n",
    "\n",
    "autocorrelation_train = autocorrelation(sequences, lag, AAindex_data)\n",
    "autocorrelation_test = autocorrelation(sequences_test, lag, AAindex_data)\n",
    "len(autocorrelation_train),len(autocorrelation_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:37:14.787868Z",
     "start_time": "2024-09-06T08:37:01.933019Z"
    }
   },
   "id": "d6efe24a2bc5de42"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "((951, 12), (105, 12))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats.stats as st\n",
    "def aaindex(path):\n",
    "    protein_list = []\n",
    "    csv_file_path = 'aaindex1.csv'\n",
    "    lag=2\n",
    "    data = []\n",
    "    with open(csv_file_path, mode='r', encoding='utf-8') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        \n",
    "        # Skip the first cell of the first row\n",
    "        for row in csv_reader:\n",
    "            # Append the row with the first cell removed to the data list\n",
    "            # data.append([float(value) for value in row[1:]])\n",
    "            data.append(row[1:])\n",
    "    data=data[1:]\n",
    "    AAindex_list = [\n",
    "        [float(value) if value not in ['NA', ''] else None for value in row]\n",
    "        for row in data\n",
    "    ]\n",
    "    # NAKH900113 【200】，KRIW710101【146】， HUTJ700103【117】，ZIMJ680103【399】，TANS770104【368】，CEDJ970105【459】，QIAN880127【283】，LEVM760107【158】\n",
    "    # selected_indices = [200, 146, 117, 399, 368,459,283, 158]\n",
    "    # AAindex_list = [AAindex_list[i] for i in selected_indices if i < len(AAindex_list)]\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line.startswith(\">\"):  # 忽略ID行，只保存序列行\n",
    "                protein_list.append(line)\n",
    "                \n",
    "    autocorrelation = []\n",
    "    for sequence in protein_list:\n",
    "        temp=[]\n",
    "        for property_values in AAindex_list:\n",
    "        # 将氨基酸序列转换为属性值序列\n",
    "        #     property_values = np.array([property_dict[aa] for aa in sequence])\n",
    "            property_values = [0 if value is None else value for value in property_values]\n",
    "            # 计算属性值的平均值\n",
    "            # print(property_values)\n",
    "            mean_value = np.mean(property_values)\n",
    "            # print(mean_value)\n",
    "            # 计算Moran自相关\n",
    "            n = len(sequence)\n",
    "            autocorr = np.sum((property_values[:-lag] - mean_value) * (property_values[lag:] - mean_value))\n",
    "            autocorr /= (n - lag)\n",
    "            temp.append(autocorr)\n",
    "\n",
    "        autocorrelation.append(temp)\n",
    "        \n",
    "    v = []\n",
    "    for i in range(len(autocorrelation)):\n",
    "        vtar = autocorrelation[i]\n",
    "        vtarv = []\n",
    "        vtar7 = 0\n",
    "        vtar8 = 0\n",
    "        vtar9 = 0\n",
    "        s = pd.Series(vtar)\n",
    "        vtar3 = np.mean(vtar)  # These 4 dimensions are relevant statistical terms\n",
    "        vtar4 = st.kurtosis(vtar)\n",
    "        vtar5 = np.var(vtar)\n",
    "        vtar6 = st.skew(vtar)\n",
    "        #for p in range(len(vtar)): # These 3 dimensions are inspired by PAFIG algorithm\n",
    "        #vtar7=vtar[p]**2+vtar7\n",
    "        #if vtar[p]>va:\n",
    "        #vtar8=vtar[p]**2+vtar8\n",
    "        #else:\n",
    "        #vtar9=vtar[p]**2+vtar9\n",
    "        vcf1 = []\n",
    "        vcf2 = []\n",
    "        for j in range(len(vtar) - 1):  #Sequence-order-correlation terms\n",
    "            vcf1.append((vtar[j] - vtar[j + 1]))\n",
    "        for k in range(len(vtar) - 2):\n",
    "            vcf2.append((vtar[k] - vtar[k + 2]))\n",
    "        vtar10 = np.mean(vcf1)\n",
    "        vtar11 = np.var(vcf1)\n",
    "        vtar11A = st.kurtosis(vcf1)\n",
    "        vtar11B = st.skew(vcf1)\n",
    "        vtar12 = np.mean(vcf2)\n",
    "        vtar13 = np.var(vcf2)\n",
    "        vtar13A = st.kurtosis(vcf2)\n",
    "        vtar13B = st.skew(vcf2)\n",
    "        vtarv.append(vtar3)\n",
    "        vtarv.append(vtar4)\n",
    "        vtarv.append(vtar5)\n",
    "        vtarv.append(vtar6)\n",
    "        #vtarv.append(vtar7/len(vtar))\n",
    "        #vtarv.append(vtar8/len(vtar))\n",
    "        #vtarv.append(vtar9/len(vtar))\n",
    "        vtarv.append(vtar10)\n",
    "        vtarv.append(vtar11)\n",
    "        vtarv.append(vtar11A)\n",
    "        vtarv.append(vtar11B)\n",
    "        vtarv.append(vtar12)\n",
    "        vtarv.append(vtar13)\n",
    "        vtarv.append(vtar13A)\n",
    "        vtarv.append(vtar13B)\n",
    "        v.append(vtarv)\n",
    "    return v\n",
    "\n",
    "train_path = '/tmp/pycharm_project_763/raw/AVP.txt'\n",
    "test_path ='/tmp/pycharm_project_763/raw/AVPT.txt'\n",
    "v_train=aaindex(train_path)\n",
    "v_test=aaindex(test_path)\n",
    "v_train = np.array(v_train)  # 转换为 NumPy 数组\n",
    "v_test = np.array(v_test)\n",
    "# print(v.shape,type(v))\n",
    "# 检查是否为二维数组\n",
    "\n",
    "\n",
    "v_train = (v_train - np.mean(v_train, axis=1, keepdims=True)) / np.std(v_train, axis=1, keepdims=True)\n",
    "v_test = (v_test - np.mean(v_test, axis=1, keepdims=True)) / np.std(v_test, axis=1, keepdims=True)\n",
    "v_train.shape,v_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:37:31.081617Z",
     "start_time": "2024-09-06T08:37:16.936875Z"
    }
   },
   "id": "3d14db058b506c00"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(951, 515)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def EGAAC(sequences, window=5):\n",
    "    if window < 1:\n",
    "        print('Error: the sliding window should be greater than zero' + '\\n\\n')\n",
    "        return None\n",
    "\n",
    "    group = {\n",
    "        'alphatic': 'GAVLMI',\n",
    "        'aromatic': 'FYW',\n",
    "        'positive_charge': 'KRH',\n",
    "        'negative_charge': 'DE',\n",
    "        'uncharged': 'STCPNQ'\n",
    "    }\n",
    "\n",
    "    groupKeys = group.keys()\n",
    "\n",
    "    encodings = []\n",
    "    header = ['#']\n",
    "    max_len = max(len(seq) for seq in sequences)  # Find the maximum length of sequences\n",
    "    for w in range(1, max_len - window + 2):\n",
    "        for g in groupKeys:\n",
    "            header.append('SW.' + str(w) + '.' + g)\n",
    "    # encodings.append(header)\n",
    "\n",
    "    for sequence in sequences:\n",
    "        code = []\n",
    "        for j in range(len(sequence) - window + 1):\n",
    "            subseq = sequence[j:j + window]\n",
    "            count = Counter(subseq)\n",
    "            myDict = {}\n",
    "            for key in groupKeys:\n",
    "                myDict[key] = sum(count[aa] for aa in group[key] if aa in count)\n",
    "            for key in groupKeys:\n",
    "                code.append(myDict[key] / window)\n",
    "        encodings.append(code)\n",
    "\n",
    "    return encodings\n",
    "\n",
    "# 示例蛋白质序列列表\n",
    "\n",
    "EGAAC_train = EGAAC(sequences, window=5)\n",
    "EGAAC_test = EGAAC(sequences_test, window=5)\n",
    "max_length1 = max(len(item) for item in EGAAC_train)\n",
    "max_length2 = max(len(item) for item in EGAAC_test)\n",
    "max_length=max(max_length1,max_length2)\n",
    "\n",
    "# 进行零填充\n",
    "EGAAC_train = np.array([np.pad(item, (0, max_length - len(item)), 'constant', constant_values=(0)) for item in EGAAC_train])\n",
    "EGAAC_test = np.array([np.pad(item, (0, max_length - len(item)), 'constant', constant_values=(0)) for item in EGAAC_test])\n",
    "EGAAC_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:37:32.930750Z",
     "start_time": "2024-09-06T08:37:32.776933Z"
    }
   },
   "id": "53942c9b85a34800"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "def calculate_properties(protein_sequences):\n",
    "    results = []\n",
    "    for sequence in protein_sequences:\n",
    "        \n",
    "        analyzed_seq = ProteinAnalysis(sequence)\n",
    "        properties = {\n",
    "            \"Molecular Weight\": analyzed_seq.molecular_weight(),\n",
    "            \"Aromaticity\": analyzed_seq.aromaticity(),\n",
    "            \"Instability Index\": analyzed_seq.instability_index(),\n",
    "            \"Isoelectric Point\": analyzed_seq.isoelectric_point(),\n",
    "            \"Secondary Structure Fraction\": analyzed_seq.secondary_structure_fraction(),  # Returns tuple (helix, turn, sheet)\n",
    "            \"Gravy\": analyzed_seq.gravy()  # Grand average of hydropathicity\n",
    "        }\n",
    "        results.append([analyzed_seq.molecular_weight(),analyzed_seq.aromaticity(),analyzed_seq.instability_index(),analyzed_seq.instability_index(),analyzed_seq.isoelectric_point(),analyzed_seq.secondary_structure_fraction()[0],analyzed_seq.secondary_structure_fraction()[1],analyzed_seq.secondary_structure_fraction()[2],analyzed_seq.gravy() ])\n",
    "        # results.append(properties)\n",
    "    return results\n",
    "properties_train=calculate_properties(sequences)\n",
    "properties_test=calculate_properties(sequences_test)\n",
    "#长度9"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:37:35.743056Z",
     "start_time": "2024-09-06T08:37:35.422426Z"
    }
   },
   "id": "c7acf983cac2b5c7"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "((105, 2140), (951, 2140))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_proteins_with_blosum62(protein_list, blosum62):\n",
    "    encoded_proteins = []\n",
    "    for protein in protein_list:\n",
    "        protein_encoding = []\n",
    "        for amino_acid in protein:\n",
    "            if amino_acid in blosum62:\n",
    "                # 将氨基酸的BLOSUM62编码添加到当前蛋白质的编码列表中\n",
    "                protein_encoding.extend(blosum62[amino_acid])\n",
    "            else:\n",
    "                # 对于不在BLOSUM62中的氨基酸，可以添加一个全0向量\n",
    "                protein_encoding.extend([0] * len(blosum62['A']))\n",
    "        encoded_proteins.append(protein_encoding)\n",
    "    return encoded_proteins\n",
    "\n",
    "# BLOSUM62矩阵定义\n",
    "blosum62 = {\n",
    "\t\t'A': [4,  -1, -2, -2, 0,  -1, -1, 0, -2,  -1, -1, -1, -1, -2, -1, 1,  0,  -3, -2, 0],  # A\n",
    "\t\t'R': [-1, 5,  0,  -2, -3, 1,  0,  -2, 0,  -3, -2, 2,  -1, -3, -2, -1, -1, -3, -2, -3], # R\n",
    "\t\t'N': [-2, 0,  6,  1,  -3, 0,  0,  0,  1,  -3, -3, 0,  -2, -3, -2, 1,  0,  -4, -2, -3], # N\n",
    "\t\t'D': [-2, -2, 1,  6,  -3, 0,  2,  -1, -1, -3, -4, -1, -3, -3, -1, 0,  -1, -4, -3, -3], # D\n",
    "\t\t'C': [0,  -3, -3, -3, 9,  -3, -4, -3, -3, -1, -1, -3, -1, -2, -3, -1, -1, -2, -2, -1], # C\n",
    "\t\t'Q': [-1, 1,  0,  0,  -3, 5,  2,  -2, 0,  -3, -2, 1,  0,  -3, -1, 0,  -1, -2, -1, -2], # Q\n",
    "\t\t'E': [-1, 0,  0,  2,  -4, 2,  5,  -2, 0,  -3, -3, 1,  -2, -3, -1, 0,  -1, -3, -2, -2], # E\n",
    "\t\t'G': [0,  -2, 0,  -1, -3, -2, -2, 6,  -2, -4, -4, -2, -3, -3, -2, 0,  -2, -2, -3, -3], # G\n",
    "\t\t'H': [-2, 0,  1,  -1, -3, 0,  0,  -2, 8,  -3, -3, -1, -2, -1, -2, -1, -2, -2, 2,  -3], # H\n",
    "\t\t'I': [-1, -3, -3, -3, -1, -3, -3, -4, -3, 4,  2,  -3, 1,  0,  -3, -2, -1, -3, -1, 3],  # I\n",
    "\t\t'L': [-1, -2, -3, -4, -1, -2, -3, -4, -3, 2,  4,  -2, 2,  0,  -3, -2, -1, -2, -1, 1],  # L\n",
    "\t\t'K': [-1, 2,  0,  -1, -3, 1,  1,  -2, -1, -3, -2, 5,  -1, -3, -1, 0,  -1, -3, -2, -2], # K\n",
    "\t\t'M': [-1, -1, -2, -3, -1, 0,  -2, -3, -2, 1,  2,  -1, 5,  0,  -2, -1, -1, -1, -1, 1],  # M\n",
    "\t\t'F': [-2, -3, -3, -3, -2, -3, -3, -3, -1, 0,  0,  -3, 0,  6,  -4, -2, -2, 1,  3,  -1], # F\n",
    "\t\t'P': [-1, -2, -2, -1, -3, -1, -1, -2, -2, -3, -3, -1, -2, -4, 7,  -1, -1, -4, -3, -2], # P\n",
    "\t\t'S': [1,  -1, 1,  0,  -1, 0,  0,  0,  -1, -2, -2, 0,  -1, -2, -1, 4,  1,  -3, -2, -2], # S\n",
    "\t\t'T': [0,  -1, 0,  -1, -1, -1, -1, -2, -2, -1, -1, -1, -1, -2, -1, 1,  5,  -2, -2, 0],  # T\n",
    "\t\t'W': [-3, -3, -4, -4, -2, -2, -3, -2, -2, -3, -2, -3, -1, 1,  -4, -3, -2, 11, 2,  -3], # W\n",
    "\t\t'Y': [-2, -2, -2, -3, -2, -1, -2, -3, 2,  -1, -1, -2, -1, 3,  -3, -2, -2, 2,  7,  -1], # Y\n",
    "\t\t'V': [0,  -3, -3, -3, -1, -2, -2, -3, -3, 3,  1,  -2, 1,  -1, -2, -2, 0,  -3, -1, 4],  # V\n",
    "\t\t'-': [0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],  # -\n",
    "\t}\n",
    "\n",
    "# 示例使用\n",
    "\n",
    "blosum62_train = encode_proteins_with_blosum62(sequences, blosum62)\n",
    "blosum62_test = encode_proteins_with_blosum62(sequences_test, blosum62)\n",
    "\n",
    "max_length1 = max(len(item) for item in blosum62_train)\n",
    "max_length2 = max(len(item) for item in blosum62_test)\n",
    "max_length=max(max_length1,max_length2)\n",
    "\n",
    "# 进行零填充\n",
    "blosum62_train = np.array([np.pad(item, (0, max_length - len(item)), 'constant', constant_values=(0)) for item in blosum62_train])\n",
    "blosum62_test = np.array([np.pad(item, (0, max_length - len(item)), 'constant', constant_values=(0)) for item in blosum62_test])\n",
    "blosum62_test.shape,blosum62_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:37:36.729420Z",
     "start_time": "2024-09-06T08:37:36.635752Z"
    }
   },
   "id": "91de3c66a3f8fa45"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "((951, 2140), (105, 2140))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_encode_proteins(protein_list):\n",
    "    # 定义氨基酸的独热编码字典\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'  # 常见的20种氨基酸\n",
    "    aa_to_onehot = {aa: np.eye(len(amino_acids))[i] for i, aa in enumerate(amino_acids)}\n",
    "\n",
    "    one_hot_encoded = []\n",
    "\n",
    "    for protein in protein_list:\n",
    "        # 将蛋白质序列转换为独热编码\n",
    "        encoded = [aa_to_onehot[aa] for aa in protein if aa in aa_to_onehot]\n",
    "        \n",
    "        # 将编码展平成一维向量\n",
    "        encoded_flattened = np.array(encoded).flatten()\n",
    "        \n",
    "        \n",
    "        one_hot_encoded.append(encoded_flattened)\n",
    "\n",
    "    return one_hot_encoded\n",
    "\n",
    "# 示例使用\n",
    "\n",
    "one_hot_train = one_hot_encode_proteins(sequences)\n",
    "one_hot_test = one_hot_encode_proteins(sequences_test)\n",
    "\n",
    "max_length1 = max(len(item) for item in one_hot_train)\n",
    "max_length2 = max(len(item) for item in one_hot_test)\n",
    "max_length=max(max_length1,max_length2)\n",
    "\n",
    "# 进行零填充\n",
    "one_hot_train = np.array([np.pad(item, (0, max_length - len(item)), 'constant', constant_values=(0)) for item in one_hot_train])\n",
    "one_hot_test = np.array([np.pad(item, (0, max_length - len(item)), 'constant', constant_values=(0)) for item in one_hot_test])\n",
    "one_hot_train.shape,one_hot_test.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:37:37.805299Z",
     "start_time": "2024-09-06T08:37:37.759683Z"
    }
   },
   "id": "1aa827bafb8b5762"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(951, 400)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def calculate_dpc(protein_list):\n",
    "    # 定义20种常见氨基酸\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    \n",
    "    # 生成所有可能的二肽组合\n",
    "    dipeptides = [aa1 + aa2 for aa1 in amino_acids for aa2 in amino_acids]\n",
    "    \n",
    "    dpc_vectors = []\n",
    "    \n",
    "    for sequence in protein_list:\n",
    "        # 统计每个序列中的二肽频率\n",
    "        counts = Counter([sequence[i:i+2] for i in range(len(sequence) - 1)])\n",
    "        \n",
    "        # 计算归一化的DPC特征\n",
    "        dpc_vector = np.array([counts[dipeptide] for dipeptide in dipeptides], dtype=float)\n",
    "        dpc_vector /= (len(sequence) - 1)  # 归一化\n",
    "        \n",
    "        dpc_vectors.append(dpc_vector)\n",
    "    \n",
    "    return np.array(dpc_vectors)\n",
    "dpc_train=calculate_dpc(sequences)\n",
    "dpc_test=calculate_dpc(sequences_test)\n",
    "dpc_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:37:39.965459Z",
     "start_time": "2024-09-06T08:37:39.876219Z"
    }
   },
   "id": "7c90595264fe55cf"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "((105, 221276), (951, 221276))"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_aaindex(filepath):\n",
    "    \"\"\"加载AAindex数据，假设第一列为描述，其余列为各个氨基酸的物理化学属性值。\"\"\"\n",
    "    aaindex_data = pd.read_csv(filepath, index_col=0)\n",
    "    return aaindex_data\n",
    "\n",
    "def encode_protein_AAindex(protein_sequences, aaindex_data):\n",
    "    \"\"\"根据AAindex编码蛋白质序列为一维特征向量。\n",
    "    \n",
    "    参数:\n",
    "        protein_sequences (list of str): 蛋白质序列列表。\n",
    "        aaindex_data (DataFrame): 从CSV文件加载的AAindex数据。\n",
    "    \n",
    "    返回:\n",
    "        list of numpy.array: 编码后的蛋白质序列特征向量列表。\n",
    "    \"\"\"\n",
    "    encoded_features = []\n",
    "    for sequence in protein_sequences:\n",
    "        # 创建一个空数组来存储每个氨基酸的特征\n",
    "        features = []\n",
    "        for amino_acid in sequence:\n",
    "            if amino_acid in aaindex_data.columns:\n",
    "                # 添加当前氨基酸的所有属性到特征列表\n",
    "                features.append(aaindex_data[amino_acid].values)\n",
    "            else:\n",
    "                # 对于不存在的氨基酸，添加一个全0向量\n",
    "                features.append(np.zeros(aaindex_data.shape[0]))\n",
    "        # 将特征列表转换为二维数组，然后展平为一维\n",
    "        flat_features = np.concatenate(features)\n",
    "        encoded_features.append(flat_features)\n",
    "    return encoded_features\n",
    "\n",
    "# Example usage\n",
    "filepath = 'aaindex2.csv'  # AAindex文件路径\n",
    "aaindex = load_aaindex(filepath)  # 加载AAindex数据\n",
    "\n",
    "  # 示例蛋白质序列\n",
    "AAindex_train = encode_protein_AAindex(sequences, aaindex)\n",
    "AAindex_test = encode_protein_AAindex(sequences_test, aaindex)\n",
    "\n",
    "max_length1 = max(len(item) for item in AAindex_train)\n",
    "max_length2 = max(len(item) for item in AAindex_test)\n",
    "max_length=max(max_length1,max_length2)\n",
    "\n",
    "# 进行零填充\n",
    "AAindex_train = np.array([np.pad(item, (0, max_length - len(item)), 'constant', constant_values=(0)) for item in AAindex_train])\n",
    "AAindex_test = np.array([np.pad(item, (0, max_length - len(item)), 'constant', constant_values=(0)) for item in AAindex_test])\n",
    "AAindex_test.shape,AAindex_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:37:41.767879Z",
     "start_time": "2024-09-06T08:37:40.705526Z"
    }
   },
   "id": "f066ddb1249593ea"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(951, 20, 951, 167, 951, 105)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aac_train),len(aac_train[0]),len(maccs_train),len(maccs_train[0]),len(v_train),len(v_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:37:42.721718Z",
     "start_time": "2024-09-06T08:37:42.699908Z"
    }
   },
   "id": "d43630ed00bfd385"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "((951, 167), (105, 167), 105)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler\n",
    "# min_max_scaler = MinMaxScaler()\n",
    "# properties_train = min_max_scaler.fit_transform(properties_train)\n",
    "# properties_test = min_max_scaler.fit_transform(properties_test)\n",
    "\n",
    "# train_encodings=np.concatenate((aac_train,maccs_train,v_train),axis=1)\n",
    "# test_encodings=np.concatenate((aac_test,maccs_test,v_test),axis=1)\n",
    "train_encodings=np.array(maccs_train)\n",
    "test_encodings=np.array(maccs_test)\n",
    "# train_encodings=autocorrelation_train\n",
    "# test_encodings=autocorrelation_test\n",
    "\n",
    "train_encodings.shape,test_encodings.shape,len(y_test)\n",
    "# one_hot_train[0],properties_train[0],aac_train[0],EGAAC_train[0],AAindex_train[0],blosum62_train[0],dpc_train[0],\n",
    "# train_encodings[2],EGAAC_train[0],properties_train[0],len(EGAAC_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:44:41.527206Z",
     "start_time": "2024-09-06T08:44:41.520587Z"
    }
   },
   "id": "b1b8801ab6cc5725"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangli/anaconda3/envs/mykan/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == \"\":\n",
      "/home/wangli/anaconda3/envs/mykan/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "/home/wangli/anaconda3/envs/mykan/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/wangli/anaconda3/envs/mykan/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(train_encodings, y, random_state=42)\n",
    "X_test, y_test = shuffle(test_encodings, y_test, random_state=42)\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)\n",
    "X_train = torch.tensor(X_train)\n",
    "y_train = torch.tensor(y_train).view(-1, 1)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_test = torch.tensor(y_test).view(-1, 1)\n",
    "X_train = torch.tensor(X_train ,dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train,dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test,dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:44:46.013183Z",
     "start_time": "2024-09-06T08:44:45.982552Z"
    }
   },
   "id": "f4de8086c0ea1557"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([951, 167])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = {}\n",
    "dataset = {\n",
    "    'train_input': X_train,\n",
    "    'test_input': X_test,\n",
    "    'train_label': y_train,\n",
    "    'test_label': y_test\n",
    "}\n",
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:44:46.845891Z",
     "start_time": "2024-09-06T08:44:46.842475Z"
    }
   },
   "id": "67ee78003569c3e8"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([105, 1])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:44:47.542507Z",
     "start_time": "2024-09-06T08:44:47.535081Z"
    }
   },
   "id": "59280a83bfb40cbe"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.78\n",
      "Training AUC: 0.86\n",
      "Test Accuracy: 0.63\n",
      "Test AUC: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangli/anaconda3/envs/mykan/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "model = SVC(kernel='linear', probability=True)  # probability=True为了后续计算AUC\n",
    "X_train,X_test=X_test,X_train\n",
    "y_train,y_test=y_test,y_train\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# 计算准确度\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# 计算AUC\n",
    "y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "train_auc = roc_auc_score(y_train, y_train_prob)\n",
    "test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Training AUC: {train_auc:.2f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "print(f\"Test AUC: {test_auc:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:44:49.698649Z",
     "start_time": "2024-09-06T08:44:49.406965Z"
    }
   },
   "id": "f34fd953745d63c0"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "model = KAN(width=[167,300,300,300,1], grid=5, k=3, seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:49:19.891265Z",
     "start_time": "2024-09-06T08:49:14.003932Z"
    }
   },
   "id": "c92d88ba1dde4f86"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.6000, AUC: 0.6230, SP: 0.7500, MCC: 0.1599, SN: 0.4000\n",
      "ACC: 0.6604, AUC(test): 0.7113, SP: 0.8125, MCC: 0.2902, SN: 0.4570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 4.61e-01 | test_loss: 4.96e-01 | reg: 0.00e+00 | :   3%| | 1/30 [00:46<22:18, 46.16s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.6762, AUC: 0.7807, SP: 0.8000, MCC: 0.3266, SN: 0.5111\n",
      "ACC: 0.7508, AUC(test): 0.8362, SP: 0.8474, MCC: 0.4855, SN: 0.6216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 4.10e-01 | test_loss: 4.46e-01 | reg: 0.00e+00 | :   7%| | 2/30 [01:21<18:31, 39.70s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.6952, AUC: 0.7707, SP: 0.7500, MCC: 0.3746, SN: 0.6222\n",
      "ACC: 0.8339, AUC(test): 0.9201, SP: 0.8768, MCC: 0.6590, SN: 0.7764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 3.46e-01 | test_loss: 4.65e-01 | reg: 0.00e+00 | :  10%| | 3/30 [02:00<17:40, 39.27s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.6762, AUC: 0.7615, SP: 0.8000, MCC: 0.3266, SN: 0.5111\n",
      "ACC: 0.8801, AUC(test): 0.9527, SP: 0.9081, MCC: 0.7545, SN: 0.8428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 3.09e-01 | test_loss: 4.70e-01 | reg: 0.00e+00 | :  13%|▏| 4/30 [02:53<18:46, 43.34s/i\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3633476/2779336304.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0;31m# results = model.train(dataset, opt=\"LBFGS\", steps=10, metrics=(train_acc, test_acc)) ,lamb=0.001 lamb_entropy=4.,lamb=0.1,lamb_l1=2.5,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;31m# lamb=0.005 train/fit\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mopt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"LBFGS\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msteps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m30\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_acc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_acc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m;\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m \u001B[0;31m# print(results['train_acc'][-1], results['test_acc'][-1])\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/MultKAN.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, dataset, opt, steps, log, lamb, lamb_l1, lamb_entropy, lamb_coef, lamb_coefdiff, update_grid, grid_update_num, loss_fn, lr, start_grid_update_step, stop_grid_update_step, batch, small_mag_threshold, small_reg_factor, metrics, save_fig, in_vars, out_vars, beta, save_fig_freq, img_folder, device, singularity_avoiding, y_th, reg_metric, display_metrics)\u001B[0m\n\u001B[1;32m    928\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    929\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mopt\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"LBFGS\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 930\u001B[0;31m                 \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    931\u001B[0m                 \u001B[0;31m# print(f\"AUC: {auc:.4f}, SP: {sp:.4f}, MCC: {mcc:.4f}, SN: {sn:.4f}\")\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    932\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mykan/lib/python3.7/site-packages/torch/optim/optimizer.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m                 \u001B[0mprofile_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"Optimizer.step#{}.step\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecord_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprofile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 140\u001B[0;31m                     \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    141\u001B[0m                     \u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_optimizer_step_code\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mykan/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/LBFGS.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    441\u001B[0m                         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_directional_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    442\u001B[0m                     loss, flat_grad, t, ls_func_evals = _strong_wolfe(\n\u001B[0;32m--> 443\u001B[0;31m                         obj_func, x_init, t, d, loss, flat_grad, gtd)\n\u001B[0m\u001B[1;32m    444\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_add_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m                 \u001B[0mopt_cond\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mflat_grad\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mabs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0mtolerance_grad\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/LBFGS.py\u001B[0m in \u001B[0;36m_strong_wolfe\u001B[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001B[0m\n\u001B[1;32m     48\u001B[0m     \u001B[0mg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmemory_format\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontiguous_format\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m     \u001B[0;31m# evaluate objective and gradient using initial step\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m     \u001B[0mf_new\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mg_new\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mobj_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m     \u001B[0mls_func_evals\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0mgtd_new\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mg_new\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/LBFGS.py\u001B[0m in \u001B[0;36mobj_func\u001B[0;34m(x, t, d)\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    440\u001B[0m                     \u001B[0;32mdef\u001B[0m \u001B[0mobj_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 441\u001B[0;31m                         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_directional_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    442\u001B[0m                     loss, flat_grad, t, ls_func_evals = _strong_wolfe(\n\u001B[1;32m    443\u001B[0m                         obj_func, x_init, t, d, loss, flat_grad, gtd)\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/LBFGS.py\u001B[0m in \u001B[0;36m_directional_evaluate\u001B[0;34m(self, closure, x, t, d)\u001B[0m\n\u001B[1;32m    288\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_directional_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclosure\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    289\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_add_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 290\u001B[0;31m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    291\u001B[0m         \u001B[0mflat_grad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_gather_flat_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    292\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_set_param\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mykan/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/MultKAN.py\u001B[0m in \u001B[0;36mclosure\u001B[0;34m()\u001B[0m\n\u001B[1;32m    875\u001B[0m             \u001B[0;32mglobal\u001B[0m \u001B[0mtrain_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreg_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    876\u001B[0m             \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 877\u001B[0;31m             \u001B[0mpred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'train_input'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtrain_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msingularity_avoiding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msingularity_avoiding\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_th\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my_th\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    878\u001B[0m             \u001B[0mtrain_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'train_label'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtrain_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    879\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_act\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/MultKAN.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x, singularity_avoiding, y_th)\u001B[0m\n\u001B[1;32m    386\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0ml\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdepth\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 388\u001B[0;31m             \u001B[0mx_numerical\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpreacts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpostacts_numerical\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpostspline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mact_fun\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0ml\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    389\u001B[0m             \u001B[0;31m#print(preacts, postacts_numerical, postspline)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    390\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/mykan/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1195\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/KANLayer.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    189\u001B[0m         \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    190\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 191\u001B[0;31m         \u001B[0mpostacts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpermute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    192\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    193\u001B[0m         \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# shape (batch, out_dim)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, matthews_corrcoef\n",
    "def train_acc():\n",
    "    pred=model(X_train)\n",
    "    with torch.no_grad():\n",
    "        pred_labels = (pred > 0.5).float() \n",
    "        auc = roc_auc_score(y_train.cpu(), pred.cpu())\n",
    "\n",
    "    # 混淆矩阵计算\n",
    "        tn, fp, fn, tp = confusion_matrix(y_train.cpu(), pred_labels.cpu()).ravel()\n",
    "\n",
    "        # Specificity (SP)\n",
    "        sp = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        \n",
    "        acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "        # Sensitivity (SN)\n",
    "        sn = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        # Matthews Correlation Coefficient (MCC)\n",
    "        mcc = matthews_corrcoef(y_train.cpu(), pred_labels.cpu())\n",
    "    print(f\"ACC: {acc:.4f}, AUC: {auc:.4f}, SP: {sp:.4f}, MCC: {mcc:.4f}, SN: {sn:.4f}\")\n",
    "    return torch.mean((torch.round(model(X_train)[:, 0]) == y_train[:, 0]).float())\n",
    "\n",
    "def test_acc():\n",
    "    pred=model(X_test)\n",
    "    with torch.no_grad():\n",
    "        pred_labels = (pred > 0.5).float() \n",
    "        auc = roc_auc_score(y_test.cpu(), pred.cpu())\n",
    "\n",
    "    # 混淆矩阵计算\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test.cpu(), pred_labels.cpu()).ravel()\n",
    "\n",
    "        # Specificity (SP)\n",
    "        sp = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        \n",
    "        acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "        # Sensitivity (SN)\n",
    "        sn = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        # Matthews Correlation Coefficient (MCC)\n",
    "        mcc = matthews_corrcoef(y_test.cpu(), pred_labels.cpu())\n",
    "    print(f\"ACC: {acc:.4f}, AUC(test): {auc:.4f}, SP: {sp:.4f}, MCC: {mcc:.4f}, SN: {sn:.4f}\")\n",
    "    return torch.mean((torch.round(model(X_test)[:, 0]) == y_test[:, 0]).float())\n",
    "\n",
    "# results = model.train(dataset, opt=\"LBFGS\", steps=10, metrics=(train_acc, test_acc)) ,lamb=0.001 lamb_entropy=4.,lamb=0.1,lamb_l1=2.5,\n",
    "# lamb=0.005 train/fit\n",
    "results = model.fit(dataset, opt=\"LBFGS\", steps=30, metrics=(train_acc, test_acc));\n",
    "# print(results['train_acc'][-1], results['test_acc'][-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T08:52:15.453859Z",
     "start_time": "2024-09-06T08:49:22.042141Z"
    }
   },
   "id": "76db8c058c2b606e"
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_711569/4072264856.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrefine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/pycharm_project_763/kan3/MultKAN.py\u001B[0m in \u001B[0;36mrefine\u001B[0;34m(self, new_grid)\u001B[0m\n\u001B[1;32m    468\u001B[0m                      device=self.device)\n\u001B[1;32m    469\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 470\u001B[0;31m         \u001B[0mmodel_new\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minitialize_from_another_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcache_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    471\u001B[0m         \u001B[0mmodel_new\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcache_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcache_data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    472\u001B[0m         \u001B[0mmodel_new\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnew_grid\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan3/MultKAN.py\u001B[0m in \u001B[0;36minitialize_from_another_model\u001B[0;34m(self, another_model, x)\u001B[0m\n\u001B[1;32m    384\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    385\u001B[0m             \u001B[0;31m# spb = spb_parent\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 386\u001B[0;31m             \u001B[0mpreacts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0manother_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspline_preacts\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0ml\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    387\u001B[0m             \u001B[0mpostsplines\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0manother_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspline_postsplines\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0ml\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    388\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mact_fun\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0ml\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcoef\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcurve2coef\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreacts\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpostsplines\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpermute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mspb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mspb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model = model.refine(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-24T02:29:51.153890Z",
     "start_time": "2024-08-24T02:29:50.946270Z"
    }
   },
   "id": "fd270700270b49d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, matthews_corrcoef\n",
    "def train_acc():\n",
    "    pred=model(X_train)\n",
    "    with torch.no_grad():\n",
    "        pred_labels = (pred > 0.5).float() \n",
    "        auc = roc_auc_score(y_train.cpu(), pred.cpu())\n",
    "\n",
    "    # 混淆矩阵计算\n",
    "        tn, fp, fn, tp = confusion_matrix(y_train.cpu(), pred_labels.cpu()).ravel()\n",
    "\n",
    "        # Specificity (SP)\n",
    "        sp = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "        # Sensitivity (SN)\n",
    "        sn = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        # Matthews Correlation Coefficient (MCC)\n",
    "        mcc = matthews_corrcoef(y_train.cpu(), pred_labels.cpu())\n",
    "    print(f\"AUC: {auc:.4f}, SP: {sp:.4f}, MCC: {mcc:.4f}, SN: {sn:.4f}\")\n",
    "    return torch.mean((torch.round(model(X_train)[:, 0]) == y_train[:, 0]).float())\n",
    "\n",
    "def test_acc():\n",
    "    pred=model(X_test)\n",
    "    with torch.no_grad():\n",
    "        pred_labels = (pred > 0.5).float() \n",
    "        auc = roc_auc_score(y_test.cpu(), pred.cpu())\n",
    "\n",
    "    # 混淆矩阵计算\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test.cpu(), pred_labels.cpu()).ravel()\n",
    "\n",
    "        # Specificity (SP)\n",
    "        sp = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "        # Sensitivity (SN)\n",
    "        sn = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        # Matthews Correlation Coefficient (MCC)\n",
    "        mcc = matthews_corrcoef(y_test.cpu(), pred_labels.cpu())\n",
    "    print(f\"AUC(test): {auc:.4f}, SP: {sp:.4f}, MCC: {mcc:.4f}, SN: {sn:.4f}\")\n",
    "    return torch.mean((torch.round(model(X_test)[:, 0]) == y_test[:, 0]).float())\n",
    "\n",
    "# results = model.train(dataset, opt=\"LBFGS\", steps=10, metrics=(train_acc, test_acc)) ,lamb=0.001 lamb_entropy=4.,lamb=0.1,lamb_l1=2.5,\n",
    "# lamb=0.005 train/fit\n",
    "results = model.fit(dataset, opt=\"LBFGS\", steps=5, metrics=(train_acc, test_acc));\n",
    "print(results['train_acc'][-1], results['test_acc'][-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-29T07:54:56.531883Z"
    }
   },
   "id": "def0d86be73b1a20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50,50)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "mlp.fit(X_train, y_train)\n",
    "predictions_train = mlp.predict(X_train)\n",
    "predictions_test = mlp.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "train_accuracy = accuracy_score(y_train, predictions_train)\n",
    "test_accuracy = accuracy_score(y_test, predictions_test)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-08-29T07:43:51.744772Z"
    }
   },
   "id": "6ee8b621a5c4d943"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangli/anaconda3/envs/transformer-env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.59\n",
      "Test Accuracy: 0.66\n",
      "Training AUC: 0.60\n",
      "Test AUC: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|                                                           | 0/30 [11:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_834928/2779336304.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0;31m# results = model.train(dataset, opt=\"LBFGS\", steps=10, metrics=(train_acc, test_acc)) ,lamb=0.001 lamb_entropy=4.,lamb=0.1,lamb_l1=2.5,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;31m# lamb=0.005 train/fit\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mopt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"LBFGS\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msteps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m30\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_acc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_acc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m;\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m \u001B[0;31m# print(results['train_acc'][-1], results['test_acc'][-1])\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/MultKAN.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, dataset, opt, steps, log, lamb, lamb_l1, lamb_entropy, lamb_coef, lamb_coefdiff, update_grid, grid_update_num, loss_fn, lr, start_grid_update_step, stop_grid_update_step, batch, small_mag_threshold, small_reg_factor, metrics, save_fig, in_vars, out_vars, beta, save_fig_freq, img_folder, device, singularity_avoiding, y_th, reg_metric, display_metrics)\u001B[0m\n\u001B[1;32m    928\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    929\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mopt\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"LBFGS\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 930\u001B[0;31m                 \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    931\u001B[0m                 \u001B[0;31m# print(f\"AUC: {auc:.4f}, SP: {sp:.4f}, MCC: {mcc:.4f}, SN: {sn:.4f}\")\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    932\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/transformer-env/lib/python3.7/site-packages/torch/optim/optimizer.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m                 \u001B[0mprofile_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"Optimizer.step#{}.step\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecord_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprofile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 140\u001B[0;31m                     \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    141\u001B[0m                     \u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_optimizer_step_code\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/transformer-env/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/LBFGS.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    441\u001B[0m                         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_directional_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    442\u001B[0m                     loss, flat_grad, t, ls_func_evals = _strong_wolfe(\n\u001B[0;32m--> 443\u001B[0;31m                         obj_func, x_init, t, d, loss, flat_grad, gtd)\n\u001B[0m\u001B[1;32m    444\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_add_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m                 \u001B[0mopt_cond\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mflat_grad\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mabs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0mtolerance_grad\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/LBFGS.py\u001B[0m in \u001B[0;36m_strong_wolfe\u001B[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001B[0m\n\u001B[1;32m     48\u001B[0m     \u001B[0mg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmemory_format\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontiguous_format\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m     \u001B[0;31m# evaluate objective and gradient using initial step\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m     \u001B[0mf_new\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mg_new\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mobj_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m     \u001B[0mls_func_evals\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0mgtd_new\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mg_new\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/LBFGS.py\u001B[0m in \u001B[0;36mobj_func\u001B[0;34m(x, t, d)\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    440\u001B[0m                     \u001B[0;32mdef\u001B[0m \u001B[0mobj_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 441\u001B[0;31m                         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_directional_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    442\u001B[0m                     loss, flat_grad, t, ls_func_evals = _strong_wolfe(\n\u001B[1;32m    443\u001B[0m                         obj_func, x_init, t, d, loss, flat_grad, gtd)\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/LBFGS.py\u001B[0m in \u001B[0;36m_directional_evaluate\u001B[0;34m(self, closure, x, t, d)\u001B[0m\n\u001B[1;32m    288\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_directional_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclosure\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    289\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_add_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 290\u001B[0;31m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    291\u001B[0m         \u001B[0mflat_grad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_gather_flat_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    292\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_set_param\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/transformer-env/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/MultKAN.py\u001B[0m in \u001B[0;36mclosure\u001B[0;34m()\u001B[0m\n\u001B[1;32m    886\u001B[0m                 \u001B[0mreg_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mobjective\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_loss\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mlamb\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mreg_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 888\u001B[0;31m             \u001B[0mobjective\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    889\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    890\u001B[0m             \u001B[0;31m# with torch.no_grad():\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/transformer-env/lib/python3.7/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    487\u001B[0m             )\n\u001B[1;32m    488\u001B[0m         torch.autograd.backward(\n\u001B[0;32m--> 489\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    490\u001B[0m         )\n\u001B[1;32m    491\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/transformer-env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    197\u001B[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[1;32m    198\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 199\u001B[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[1;32m    200\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    201\u001B[0m def grad(\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "model = SVC(kernel='linear', probability=True)  # probability=True为了后续计算AUC\n",
    "X_train,X_test=X_test,X_train\n",
    "y_train,y_test=y_test,y_train\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# 计算准确度\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# 计算AUC\n",
    "y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "train_auc = roc_auc_score(y_train, y_train_prob)\n",
    "test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "print(f\"Training AUC: {train_auc:.2f}\")\n",
    "print(f\"Test AUC: {test_auc:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T07:54:56.531965Z",
     "start_time": "2024-08-24T05:05:31.163892Z"
    }
   },
   "id": "4fdec9086f11ac96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7691c6d008104f7a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
