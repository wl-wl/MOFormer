{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-25T07:39:57.715361Z",
     "start_time": "2024-07-25T07:39:55.366890Z"
    }
   },
   "outputs": [],
   "source": [
    "from kan import KAN\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "import numpy as np\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "protein_feature_train = []\n",
    "\n",
    "# 打开并读取文件\n",
    "with open('/tmp/pycharm_project_763/feature/feature_train/phychem_train.txt', 'r') as file:\n",
    "    # 逐行读取文件内容\n",
    "    for line in file:\n",
    "        if line.startswith('>'):  # 跳过以'>'开头的行（序列标识行）\n",
    "            continue\n",
    "        # 分割行中的每个特征并转换为浮点数\n",
    "        features = [float(x) for x in line.strip().split('\\t')]\n",
    "        # 将特征列表添加到主列表中\n",
    "        protein_feature_train.append(features)\n",
    "# protein_feature_train[:5]   "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T07:39:57.715910Z",
     "start_time": "2024-07-25T07:39:57.715149Z"
    }
   },
   "id": "d3297611f544747a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "protein_feature_test = []\n",
    "\n",
    "# 打开并读取文件\n",
    "with open('/tmp/pycharm_project_763/feature/feature_test/phychem_test.txt', 'r') as file:\n",
    "    # 逐行读取文件内容\n",
    "    for line in file:\n",
    "        if line.startswith('>'):  # 跳过以'>'开头的行（序列标识行）\n",
    "            continue\n",
    "        # 分割行中的每个特征并转换为浮点数\n",
    "        features = [float(x) for x in line.strip().split('\\t')]\n",
    "        # 将特征列表添加到主列表中\n",
    "        protein_feature_test.append(features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T07:39:59.201684Z",
     "start_time": "2024-07-25T07:39:59.195721Z"
    }
   },
   "id": "80bdfa3241055fcb"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/tmp/pycharm_project_763/data/trainCPP.csv')\n",
    "\n",
    "# 提取序列和标签\n",
    "sequences = df['sequence'].tolist()\n",
    "y = df['label'].tolist()\n",
    "\n",
    "df2= pd.read_csv('/tmp/pycharm_project_763/data/testCPP.csv')\n",
    "\n",
    "# 提取序列和标签\n",
    "sequences_test = df2['sequence'].tolist()\n",
    "y_test = df2['label'].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T07:39:59.798002Z",
     "start_time": "2024-07-25T07:39:59.789803Z"
    }
   },
   "id": "fb1ccdd0941e2277"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(protein_feature_train, y, random_state=42)\n",
    "X_test, y_test = shuffle(protein_feature_test, y_test, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T07:40:00.363181Z",
     "start_time": "2024-07-25T07:40:00.357662Z"
    }
   },
   "id": "5e6fc959510d47cf"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T07:40:01.051372Z",
     "start_time": "2024-07-25T07:40:01.045838Z"
    }
   },
   "id": "ac240271ac2d6b84"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(1164, 24)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T07:40:01.613661Z",
     "start_time": "2024-07-25T07:40:01.585535Z"
    }
   },
   "id": "5315a155064dae1c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "y_train = y_train.reshape((y_train.shape[0], 1))\n",
    "y_test = y_test.reshape((y_test.shape[0], 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T07:40:02.345918Z",
     "start_time": "2024-07-25T07:40:02.336730Z"
    }
   },
   "id": "7c7e2a47b58cb99f"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50,50)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T07:40:02.995532Z",
     "start_time": "2024-07-25T07:40:02.990265Z"
    }
   },
   "id": "a010b0dfe2540b2"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "mlp = MLPClassifier(max_iter=30, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T07:40:03.692097Z",
     "start_time": "2024-07-25T07:40:03.688350Z"
    }
   },
   "id": "43a5bfd05e79b5b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangli/anaconda3/envs/transformer-env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/wangli/anaconda3/envs/transformer-env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=3, estimator=MLPClassifier(max_iter=30, random_state=1),\n             n_jobs=-1,\n             param_grid={'activation': ['tanh', 'relu'],\n                         'alpha': [0.0001, 0.05],\n                         'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n                         'learning_rate': ['constant', 'adaptive'],\n                         'solver': ['sgd', 'adam']},\n             verbose=2)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建GridSearchCV对象\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T07:40:07.343684Z",
     "start_time": "2024-07-25T07:40:04.314462Z"
    }
   },
   "id": "7e3e3246e625213f"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# 最佳参数和模型\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "best_mlp = grid_search.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T07:40:08.534012Z",
     "start_time": "2024-07-25T07:40:08.533643Z"
    }
   },
   "id": "c2e49278724847f9"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 使用最佳模型进行预测\n",
    "predictions_train = best_mlp.predict(X_train)\n",
    "predictions_test = best_mlp.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T07:40:09.449156Z",
     "start_time": "2024-07-25T07:40:09.417483Z"
    }
   },
   "id": "f5ffbfa1414c8d09"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7457\n",
      "Test Accuracy: 0.7124\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = accuracy_score(y_train, predictions_train)\n",
    "test_accuracy = accuracy_score(y_test, predictions_test)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T07:40:10.264563Z",
     "start_time": "2024-07-25T07:40:10.256286Z"
    }
   },
   "id": "7242cf240cd23cbc"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, random_state=1,\n",
    "                    learning_rate_init=.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-22T10:50:30.115522Z",
     "start_time": "2024-07-22T10:50:30.110022Z"
    }
   },
   "id": "64f7018c3477a574"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangli/anaconda3/envs/transformer-env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.71159803\n",
      "Iteration 2, loss = 0.66928930\n",
      "Iteration 3, loss = 0.65123909\n",
      "Iteration 4, loss = 0.63663658\n",
      "Iteration 5, loss = 0.62767529\n",
      "Iteration 6, loss = 0.61979814\n",
      "Iteration 7, loss = 0.61249474\n",
      "Iteration 8, loss = 0.60339833\n",
      "Iteration 9, loss = 0.59612704\n",
      "Iteration 10, loss = 0.59018149\n",
      "Iteration 11, loss = 0.58316539\n",
      "Iteration 12, loss = 0.57642724\n",
      "Iteration 13, loss = 0.57137561\n",
      "Iteration 14, loss = 0.56464076\n",
      "Iteration 15, loss = 0.56007672\n",
      "Iteration 16, loss = 0.55377403\n",
      "Iteration 17, loss = 0.54935112\n",
      "Iteration 18, loss = 0.54339061\n",
      "Iteration 19, loss = 0.53814306\n",
      "Iteration 20, loss = 0.53493608\n",
      "Iteration 21, loss = 0.52850590\n",
      "Iteration 22, loss = 0.52281338\n",
      "Iteration 23, loss = 0.51865820\n",
      "Iteration 24, loss = 0.51370225\n",
      "Iteration 25, loss = 0.50791669\n",
      "Iteration 26, loss = 0.50459006\n",
      "Iteration 27, loss = 0.50010764\n",
      "Iteration 28, loss = 0.49475367\n",
      "Iteration 29, loss = 0.49009283\n",
      "Iteration 30, loss = 0.48738877\n",
      "Iteration 31, loss = 0.48313797\n",
      "Iteration 32, loss = 0.47835426\n",
      "Iteration 33, loss = 0.47461766\n",
      "Iteration 34, loss = 0.47050550\n",
      "Iteration 35, loss = 0.47057124\n",
      "Iteration 36, loss = 0.46234118\n",
      "Iteration 37, loss = 0.46057973\n",
      "Iteration 38, loss = 0.45539485\n",
      "Iteration 39, loss = 0.45214787\n",
      "Iteration 40, loss = 0.44855745\n",
      "Iteration 41, loss = 0.44467668\n",
      "Iteration 42, loss = 0.44126043\n",
      "Iteration 43, loss = 0.43869178\n",
      "Iteration 44, loss = 0.43553015\n",
      "Iteration 45, loss = 0.43212545\n",
      "Iteration 46, loss = 0.43029842\n",
      "Iteration 47, loss = 0.42558542\n",
      "Iteration 48, loss = 0.42316261\n",
      "Iteration 49, loss = 0.42439507\n",
      "Iteration 50, loss = 0.41693834\n",
      "Iteration 51, loss = 0.41457811\n",
      "Iteration 52, loss = 0.41254293\n",
      "Iteration 53, loss = 0.40781036\n",
      "Iteration 54, loss = 0.40636262\n",
      "Iteration 55, loss = 0.40485165\n",
      "Iteration 56, loss = 0.40040201\n",
      "Iteration 57, loss = 0.39613084\n",
      "Iteration 58, loss = 0.39593415\n",
      "Iteration 59, loss = 0.39211276\n",
      "Iteration 60, loss = 0.38867199\n",
      "Iteration 61, loss = 0.38996880\n",
      "Iteration 62, loss = 0.38241329\n",
      "Iteration 63, loss = 0.38026827\n",
      "Iteration 64, loss = 0.37834961\n",
      "Iteration 65, loss = 0.37715088\n",
      "Iteration 66, loss = 0.37307184\n",
      "Iteration 67, loss = 0.37315793\n",
      "Iteration 68, loss = 0.36947476\n",
      "Iteration 69, loss = 0.36704160\n",
      "Iteration 70, loss = 0.36425496\n",
      "Iteration 71, loss = 0.36157031\n",
      "Iteration 72, loss = 0.36054473\n",
      "Iteration 73, loss = 0.35563429\n",
      "Iteration 74, loss = 0.35500309\n",
      "Iteration 75, loss = 0.35266446\n",
      "Iteration 76, loss = 0.34881060\n",
      "Iteration 77, loss = 0.34527865\n",
      "Iteration 78, loss = 0.34981246\n",
      "Iteration 79, loss = 0.34528138\n",
      "Iteration 80, loss = 0.34269198\n",
      "Iteration 81, loss = 0.34099041\n",
      "Iteration 82, loss = 0.33814588\n",
      "Iteration 83, loss = 0.33574775\n",
      "Iteration 84, loss = 0.33384778\n",
      "Iteration 85, loss = 0.33450118\n",
      "Iteration 86, loss = 0.32878258\n",
      "Iteration 87, loss = 0.32640574\n",
      "Iteration 88, loss = 0.33050128\n",
      "Iteration 89, loss = 0.32350402\n",
      "Iteration 90, loss = 0.32277365\n",
      "Iteration 91, loss = 0.32239202\n",
      "Iteration 92, loss = 0.31681989\n",
      "Iteration 93, loss = 0.31410601\n",
      "Iteration 94, loss = 0.31712031\n",
      "Iteration 95, loss = 0.31647368\n",
      "Iteration 96, loss = 0.31053266\n",
      "Iteration 97, loss = 0.31023443\n",
      "Iteration 98, loss = 0.31254937\n",
      "Iteration 99, loss = 0.30482141\n",
      "Iteration 100, loss = 0.30182443\n",
      "Iteration 101, loss = 0.30213827\n",
      "Iteration 102, loss = 0.29841662\n",
      "Iteration 103, loss = 0.30196627\n",
      "Iteration 104, loss = 0.29645449\n",
      "Iteration 105, loss = 0.29929836\n",
      "Iteration 106, loss = 0.29686298\n",
      "Iteration 107, loss = 0.29303119\n",
      "Iteration 108, loss = 0.29262725\n",
      "Iteration 109, loss = 0.29528625\n",
      "Iteration 110, loss = 0.29492530\n",
      "Iteration 111, loss = 0.29055109\n",
      "Iteration 112, loss = 0.29372891\n",
      "Iteration 113, loss = 0.28152970\n",
      "Iteration 114, loss = 0.28237384\n",
      "Iteration 115, loss = 0.28242862\n",
      "Iteration 116, loss = 0.27981749\n",
      "Iteration 117, loss = 0.27893996\n",
      "Iteration 118, loss = 0.27945753\n",
      "Iteration 119, loss = 0.27150301\n",
      "Iteration 120, loss = 0.26990383\n",
      "Iteration 121, loss = 0.27655337\n",
      "Iteration 122, loss = 0.27618723\n",
      "Iteration 123, loss = 0.26610337\n",
      "Iteration 124, loss = 0.26263679\n",
      "Iteration 125, loss = 0.26304271\n",
      "Iteration 126, loss = 0.26153410\n",
      "Iteration 127, loss = 0.26118989\n",
      "Iteration 128, loss = 0.26223069\n",
      "Iteration 129, loss = 0.26214935\n",
      "Iteration 130, loss = 0.25425722\n",
      "Iteration 131, loss = 0.25718377\n",
      "Iteration 132, loss = 0.25702722\n",
      "Iteration 133, loss = 0.25358027\n",
      "Iteration 134, loss = 0.25282592\n",
      "Iteration 135, loss = 0.25027464\n",
      "Iteration 136, loss = 0.25859451\n",
      "Iteration 137, loss = 0.25075363\n",
      "Iteration 138, loss = 0.25319025\n",
      "Iteration 139, loss = 0.25130615\n",
      "Iteration 140, loss = 0.24942932\n",
      "Iteration 141, loss = 0.24235084\n",
      "Iteration 142, loss = 0.25103001\n",
      "Iteration 143, loss = 0.24467509\n",
      "Iteration 144, loss = 0.23867022\n",
      "Iteration 145, loss = 0.23842274\n",
      "Iteration 146, loss = 0.23873072\n",
      "Iteration 147, loss = 0.23955753\n",
      "Iteration 148, loss = 0.23874478\n",
      "Iteration 149, loss = 0.23672534\n",
      "Iteration 150, loss = 0.23431013\n",
      "Iteration 151, loss = 0.23011620\n",
      "Iteration 152, loss = 0.23701264\n",
      "Iteration 153, loss = 0.24151848\n",
      "Iteration 154, loss = 0.23868485\n",
      "Iteration 155, loss = 0.23894479\n",
      "Iteration 156, loss = 0.22508450\n",
      "Iteration 157, loss = 0.22941397\n",
      "Iteration 158, loss = 0.22754107\n",
      "Iteration 159, loss = 0.22796593\n",
      "Iteration 160, loss = 0.23327435\n",
      "Iteration 161, loss = 0.21958690\n",
      "Iteration 162, loss = 0.21870931\n",
      "Iteration 163, loss = 0.22420668\n",
      "Iteration 164, loss = 0.22350533\n",
      "Iteration 165, loss = 0.21953702\n",
      "Iteration 166, loss = 0.21566037\n",
      "Iteration 167, loss = 0.21750362\n",
      "Iteration 168, loss = 0.21843697\n",
      "Iteration 169, loss = 0.21421881\n",
      "Iteration 170, loss = 0.21647210\n",
      "Iteration 171, loss = 0.21317056\n",
      "Iteration 172, loss = 0.20995677\n",
      "Iteration 173, loss = 0.21392346\n",
      "Iteration 174, loss = 0.21176661\n",
      "Iteration 175, loss = 0.21469187\n",
      "Iteration 176, loss = 0.21526465\n",
      "Iteration 177, loss = 0.20966544\n",
      "Iteration 178, loss = 0.20297526\n",
      "Iteration 179, loss = 0.21945148\n",
      "Iteration 180, loss = 0.20672683\n",
      "Iteration 181, loss = 0.21008147\n",
      "Iteration 182, loss = 0.20467544\n",
      "Iteration 183, loss = 0.20978020\n",
      "Iteration 184, loss = 0.20103783\n",
      "Iteration 185, loss = 0.20059245\n",
      "Iteration 186, loss = 0.20092666\n",
      "Iteration 187, loss = 0.20736496\n",
      "Iteration 188, loss = 0.20537865\n",
      "Iteration 189, loss = 0.20249677\n",
      "Iteration 190, loss = 0.19767135\n",
      "Iteration 191, loss = 0.19848100\n",
      "Iteration 192, loss = 0.20168949\n",
      "Iteration 193, loss = 0.19848146\n",
      "Iteration 194, loss = 0.19345661\n",
      "Iteration 195, loss = 0.19740538\n",
      "Iteration 196, loss = 0.19563154\n",
      "Iteration 197, loss = 0.19048101\n",
      "Iteration 198, loss = 0.19606851\n",
      "Iteration 199, loss = 0.19314662\n",
      "Iteration 200, loss = 0.21123469\n",
      "Iteration 201, loss = 0.19157981\n",
      "Iteration 202, loss = 0.19122139\n",
      "Iteration 203, loss = 0.19197129\n",
      "Iteration 204, loss = 0.19690489\n",
      "Iteration 205, loss = 0.18538848\n",
      "Iteration 206, loss = 0.19569896\n",
      "Iteration 207, loss = 0.18764863\n",
      "Iteration 208, loss = 0.19088561\n",
      "Iteration 209, loss = 0.19299842\n",
      "Iteration 210, loss = 0.18690629\n",
      "Iteration 211, loss = 0.20026388\n",
      "Iteration 212, loss = 0.18072953\n",
      "Iteration 213, loss = 0.18176373\n",
      "Iteration 214, loss = 0.18166905\n",
      "Iteration 215, loss = 0.18211198\n",
      "Iteration 216, loss = 0.18972631\n",
      "Iteration 217, loss = 0.17684957\n",
      "Iteration 218, loss = 0.18533771\n",
      "Iteration 219, loss = 0.18264534\n",
      "Iteration 220, loss = 0.17815428\n",
      "Iteration 221, loss = 0.17519833\n",
      "Iteration 222, loss = 0.17197281\n",
      "Iteration 223, loss = 0.17184750\n",
      "Iteration 224, loss = 0.16917307\n",
      "Iteration 225, loss = 0.17835728\n",
      "Iteration 226, loss = 0.18011636\n",
      "Iteration 227, loss = 0.16949877\n",
      "Iteration 228, loss = 0.17624808\n",
      "Iteration 229, loss = 0.17414939\n",
      "Iteration 230, loss = 0.17540885\n",
      "Iteration 231, loss = 0.17255269\n",
      "Iteration 232, loss = 0.17483949\n",
      "Iteration 233, loss = 0.17066135\n",
      "Iteration 234, loss = 0.16581954\n",
      "Iteration 235, loss = 0.18228243\n",
      "Iteration 236, loss = 0.17644471\n",
      "Iteration 237, loss = 0.17216086\n",
      "Iteration 238, loss = 0.16734945\n",
      "Iteration 239, loss = 0.16900745\n",
      "Iteration 240, loss = 0.16271013\n",
      "Iteration 241, loss = 0.17920651\n",
      "Iteration 242, loss = 0.16272544\n",
      "Iteration 243, loss = 0.16488440\n",
      "Iteration 244, loss = 0.17021940\n",
      "Iteration 245, loss = 0.17047626\n",
      "Iteration 246, loss = 0.15703435\n",
      "Iteration 247, loss = 0.15954754\n",
      "Iteration 248, loss = 0.16881867\n",
      "Iteration 249, loss = 0.17099521\n",
      "Iteration 250, loss = 0.15880938\n",
      "Iteration 251, loss = 0.15992904\n",
      "Iteration 252, loss = 0.17558172\n",
      "Iteration 253, loss = 0.16748040\n",
      "Iteration 254, loss = 0.15874654\n",
      "Iteration 255, loss = 0.15000657\n",
      "Iteration 256, loss = 0.16490191\n",
      "Iteration 257, loss = 0.15457031\n",
      "Iteration 258, loss = 0.16048607\n",
      "Iteration 259, loss = 0.15473105\n",
      "Iteration 260, loss = 0.15282284\n",
      "Iteration 261, loss = 0.16441403\n",
      "Iteration 262, loss = 0.15304609\n",
      "Iteration 263, loss = 0.14915718\n",
      "Iteration 264, loss = 0.17001134\n",
      "Iteration 265, loss = 0.15013765\n",
      "Iteration 266, loss = 0.16446670\n",
      "Iteration 267, loss = 0.16082652\n",
      "Iteration 268, loss = 0.15493769\n",
      "Iteration 269, loss = 0.14549230\n",
      "Iteration 270, loss = 0.14980737\n",
      "Iteration 271, loss = 0.15132547\n",
      "Iteration 272, loss = 0.15686342\n",
      "Iteration 273, loss = 0.15003088\n",
      "Iteration 274, loss = 0.16239493\n",
      "Iteration 275, loss = 0.13983549\n",
      "Iteration 276, loss = 0.14276131\n",
      "Iteration 277, loss = 0.14452404\n",
      "Iteration 278, loss = 0.14640031\n",
      "Iteration 279, loss = 0.15005214\n",
      "Iteration 280, loss = 0.14500805\n",
      "Iteration 281, loss = 0.17219844\n",
      "Iteration 282, loss = 0.14001219\n",
      "Iteration 283, loss = 0.15176383\n",
      "Iteration 284, loss = 0.14462959\n",
      "Iteration 285, loss = 0.13893001\n",
      "Iteration 286, loss = 0.16431492\n",
      "Iteration 287, loss = 0.14221307\n",
      "Iteration 288, loss = 0.13900977\n",
      "Iteration 289, loss = 0.13135736\n",
      "Iteration 290, loss = 0.13324092\n",
      "Iteration 291, loss = 0.15100348\n",
      "Iteration 292, loss = 0.14938636\n",
      "Iteration 293, loss = 0.13855892\n",
      "Iteration 294, loss = 0.14105767\n",
      "Iteration 295, loss = 0.16171518\n",
      "Iteration 296, loss = 0.14009052\n",
      "Iteration 297, loss = 0.13438178\n",
      "Iteration 298, loss = 0.13759976\n",
      "Iteration 299, loss = 0.13485107\n",
      "Iteration 300, loss = 0.14392479\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": "MLPClassifier(learning_rate_init=0.1, max_iter=300, random_state=1,\n              solver='sgd', verbose=10)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-22T10:50:35.642526Z",
     "start_time": "2024-07-22T10:50:31.092872Z"
    }
   },
   "id": "6189c712cf3f6308"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9545\n",
      "Test Accuracy: 0.8027\n"
     ]
    }
   ],
   "source": [
    "predictions_train = mlp.predict(X_train)\n",
    "predictions_test = mlp.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "train_accuracy = accuracy_score(y_train, predictions_train)\n",
    "test_accuracy = accuracy_score(y_test, predictions_test)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-22T10:50:37.292Z",
     "start_time": "2024-07-22T10:50:37.277879Z"
    }
   },
   "id": "d767232d0086b004"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9545\n",
      "Test Accuracy: 0.8027\n",
      "Train AUC: 0.9931\n",
      "Test AUC: 0.8762\n",
      "Train Specificity: 0.9296\n",
      "Test Specificity: 0.7450\n",
      "Train MCC: 0.9101\n",
      "Test MCC: 0.6092\n",
      "Train Sensitivity: 0.9794\n",
      "Test Sensitivity: 0.8600\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, matthews_corrcoef, recall_score\n",
    "\n",
    "probabilities_train = mlp.predict_proba(X_train)[:, 1]\n",
    "probabilities_test = mlp.predict_proba(X_test)[:, 1]\n",
    "train_auc = roc_auc_score(y_train, probabilities_train)\n",
    "test_auc = roc_auc_score(y_test, probabilities_test)\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm_train = confusion_matrix(y_train, predictions_train)\n",
    "cm_test = confusion_matrix(y_test, predictions_test)\n",
    "\n",
    "# 计算Specificity (SP)\n",
    "tn_train, fp_train, fn_train, tp_train = cm_train.ravel()\n",
    "tn_test, fp_test, fn_test, tp_test = cm_test.ravel()\n",
    "train_specificity = tn_train / (tn_train + fp_train)\n",
    "test_specificity = tn_test / (tn_test + fp_test)\n",
    "\n",
    "# 计算MCC\n",
    "train_mcc = matthews_corrcoef(y_train, predictions_train)\n",
    "test_mcc = matthews_corrcoef(y_test, predictions_test)\n",
    "\n",
    "# 计算Sensitivity (SN)\n",
    "train_sensitivity = recall_score(y_train, predictions_train)\n",
    "test_sensitivity = recall_score(y_test, predictions_test)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Train AUC: {train_auc:.4f}')\n",
    "print(f'Test AUC: {test_auc:.4f}')\n",
    "print(f'Train Specificity: {train_specificity:.4f}')\n",
    "print(f'Test Specificity: {test_specificity:.4f}')\n",
    "print(f'Train MCC: {train_mcc:.4f}')\n",
    "print(f'Test MCC: {test_mcc:.4f}')\n",
    "print(f'Train Sensitivity: {train_sensitivity:.4f}')\n",
    "print(f'Test Sensitivity: {test_sensitivity:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-22T10:50:38.977049Z",
     "start_time": "2024-07-22T10:50:38.964449Z"
    }
   },
   "id": "b95f762882309e67"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ea2ec7945729c610"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2c9d61cbeee4f908"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6eb9fe8527ea7b1b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
