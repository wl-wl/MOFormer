{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-04T06:05:35.170168Z",
     "start_time": "2024-09-04T06:05:32.584220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "39\n",
      "(740, 37)\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "from kan import KAN\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "import torch\n",
    "import process as data\n",
    "import numpy as np\n",
    "\n",
    "ac_p,label=data.deal()\n",
    "aac=data.fe()\n",
    "ctd=data.CTD()\n",
    "gaac=data.gaac()\n",
    "X=np.concatenate((aac,gaac,ac_p),axis=1)\n",
    "print(X.shape)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "model = KAN(width=[37,3,1], grid=3, k=3)\n",
    "fold = 1\n",
    "\n",
    "y=label\n",
    "y=np.array(y)\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "((740, 37),\n (740,),\n array([ 0.206     ,  0.034     ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.068     ,  0.206     ,\n         0.        ,  0.        ,  0.137     ,  0.068     ,  0.206     ,\n         0.        ,  0.        ,  0.068     ,  0.        ,  0.        ,\n         0.4827586 ,  0.        ,  0.27586207,  0.        ,  0.2413793 ,\n         0.3097381 ,  1.0639765 ,  0.0568791 ,  0.86569893,  0.00607317,\n         0.10164909,  1.0124953 , -0.8127152 ,  0.017475  ,  0.11910645,\n         0.13605663, -0.3426687 ], dtype=float32),\n 0.0)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape,X[0],y[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T07:05:19.225613Z",
     "start_time": "2024-08-29T07:05:19.217792Z"
    }
   },
   "id": "8ed5c5494b4ace00"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangli/anaconda3/envs/transformer-env/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/wangli/anaconda3/envs/transformer-env/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == \"\":\n",
      "/home/wangli/anaconda3/envs/transformer-env/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "/home/wangli/anaconda3/envs/transformer-env/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42)\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)\n",
    "X_train = torch.tensor(X_train)\n",
    "y_train = torch.tensor(y_train).view(-1, 1)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_test = torch.tensor(y_test).view(-1, 1)\n",
    "X_train = torch.tensor(X_train ,dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train,dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test,dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T07:05:19.893934Z",
     "start_time": "2024-08-29T07:05:19.891740Z"
    }
   },
   "id": "8ba7cb1c1076ef0"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([555, 37]),\n torch.Size([555, 1]),\n tensor([ 0.1000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1000,  0.0000,  0.1000,\n          0.2000,  0.4000,  0.0000,  0.0500,  0.0000,  0.0000,  0.0000,  0.0000,\n          0.0000,  0.0000,  0.0000,  0.0500,  0.7000,  0.0500,  0.2000,  0.0000,\n          0.0500, -0.0806,  0.6479,  0.0078,  0.0510, -0.0031,  0.0118,  0.1250,\n          0.6300, -0.0030,  0.0134, -0.2254, -0.3329]),\n tensor([0.]))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,X_train[0],y_test[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T07:05:20.465145Z",
     "start_time": "2024-08-29T07:05:20.459623Z"
    }
   },
   "id": "4db8b57100224f1b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([555, 37])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = {}\n",
    "dataset = {\n",
    "    'train_input': X_train,\n",
    "    'test_input': X_test,\n",
    "    'train_label': y_train,\n",
    "    'test_label': y_test\n",
    "}\n",
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T07:05:21.138078Z",
     "start_time": "2024-08-29T07:05:21.109429Z"
    }
   },
   "id": "35205b519dbbfa63"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "model = KAN(width=[37,5,1], grid=7, k=9, seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T07:05:21.862406Z",
     "start_time": "2024-08-29T07:05:21.835017Z"
    }
   },
   "id": "da5c79f5445ee98d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.9189, AUC: 0.9768, SP: 0.9060, MCC: 0.8376, SN: 0.9308\n",
      "ACC: 0.9189, AUC(test): 0.9650, SP: 0.9135, MCC: 0.8364, SN: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 2.37e-01 | test_loss: 2.66e-01 | reg: 0.00e+00 | :   3%| | 1/30 [13:05<6:19:29, 785.17"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.9495, AUC: 0.9859, SP: 0.9286, MCC: 0.8994, SN: 0.9689\n",
      "ACC: 0.9135, AUC(test): 0.9581, SP: 0.9038, MCC: 0.8261, SN: 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.97e-01 | test_loss: 2.68e-01 | reg: 0.00e+00 | :   7%| | 2/30 [24:49<5:44:11, 737.55"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.9766, AUC: 0.9919, SP: 0.9699, MCC: 0.9531, SN: 0.9827\n",
      "ACC: 0.8919, AUC(test): 0.9160, SP: 0.8846, MCC: 0.7823, SN: 0.9012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.62e-01 | test_loss: 3.23e-01 | reg: 0.00e+00 | :  10%| | 3/30 [36:27<5:23:53, 719.76"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.9910, AUC: 0.9947, SP: 0.9850, MCC: 0.9820, SN: 0.9965\n",
      "ACC: 0.8919, AUC(test): 0.9021, SP: 0.9038, MCC: 0.7804, SN: 0.8765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.35e-01 | test_loss: 3.34e-01 | reg: 0.00e+00 | :  13%|▏| 4/30 [55:58<6:03:52, 839.73\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_821958/2779336304.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0;31m# results = model.train(dataset, opt=\"LBFGS\", steps=10, metrics=(train_acc, test_acc)) ,lamb=0.001 lamb_entropy=4.,lamb=0.1,lamb_l1=2.5,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;31m# lamb=0.005 train/fit\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mopt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"LBFGS\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msteps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m30\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_acc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_acc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m;\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m \u001B[0;31m# print(results['train_acc'][-1], results['test_acc'][-1])\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/MultKAN.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, dataset, opt, steps, log, lamb, lamb_l1, lamb_entropy, lamb_coef, lamb_coefdiff, update_grid, grid_update_num, loss_fn, lr, start_grid_update_step, stop_grid_update_step, batch, small_mag_threshold, small_reg_factor, metrics, save_fig, in_vars, out_vars, beta, save_fig_freq, img_folder, device, singularity_avoiding, y_th, reg_metric, display_metrics)\u001B[0m\n\u001B[1;32m    928\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    929\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mopt\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"LBFGS\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 930\u001B[0;31m                 \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    931\u001B[0m                 \u001B[0;31m# print(f\"AUC: {auc:.4f}, SP: {sp:.4f}, MCC: {mcc:.4f}, SN: {sn:.4f}\")\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    932\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/transformer-env/lib/python3.7/site-packages/torch/optim/optimizer.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m                 \u001B[0mprofile_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"Optimizer.step#{}.step\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprofiler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecord_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprofile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 140\u001B[0;31m                     \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    141\u001B[0m                     \u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_optimizer_step_code\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/transformer-env/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/LBFGS.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    441\u001B[0m                         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_directional_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    442\u001B[0m                     loss, flat_grad, t, ls_func_evals = _strong_wolfe(\n\u001B[0;32m--> 443\u001B[0;31m                         obj_func, x_init, t, d, loss, flat_grad, gtd)\n\u001B[0m\u001B[1;32m    444\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_add_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m                 \u001B[0mopt_cond\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mflat_grad\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mabs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0mtolerance_grad\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/LBFGS.py\u001B[0m in \u001B[0;36m_strong_wolfe\u001B[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001B[0m\n\u001B[1;32m     48\u001B[0m     \u001B[0mg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmemory_format\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontiguous_format\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m     \u001B[0;31m# evaluate objective and gradient using initial step\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m     \u001B[0mf_new\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mg_new\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mobj_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m     \u001B[0mls_func_evals\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0mgtd_new\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mg_new\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/LBFGS.py\u001B[0m in \u001B[0;36mobj_func\u001B[0;34m(x, t, d)\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    440\u001B[0m                     \u001B[0;32mdef\u001B[0m \u001B[0mobj_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 441\u001B[0;31m                         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_directional_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    442\u001B[0m                     loss, flat_grad, t, ls_func_evals = _strong_wolfe(\n\u001B[1;32m    443\u001B[0m                         obj_func, x_init, t, d, loss, flat_grad, gtd)\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/LBFGS.py\u001B[0m in \u001B[0;36m_directional_evaluate\u001B[0;34m(self, closure, x, t, d)\u001B[0m\n\u001B[1;32m    288\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_directional_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclosure\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    289\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_add_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 290\u001B[0;31m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    291\u001B[0m         \u001B[0mflat_grad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_gather_flat_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    292\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_set_param\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/transformer-env/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/pycharm_project_763/kan/MultKAN.py\u001B[0m in \u001B[0;36mclosure\u001B[0;34m()\u001B[0m\n\u001B[1;32m    886\u001B[0m                 \u001B[0mreg_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mobjective\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_loss\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mlamb\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mreg_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 888\u001B[0;31m             \u001B[0mobjective\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    889\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    890\u001B[0m             \u001B[0;31m# with torch.no_grad():\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/transformer-env/lib/python3.7/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    487\u001B[0m             )\n\u001B[1;32m    488\u001B[0m         torch.autograd.backward(\n\u001B[0;32m--> 489\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    490\u001B[0m         )\n\u001B[1;32m    491\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/transformer-env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    197\u001B[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[1;32m    198\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 199\u001B[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[1;32m    200\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    201\u001B[0m def grad(\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, matthews_corrcoef\n",
    "def train_acc():\n",
    "    pred=model(X_train)\n",
    "    with torch.no_grad():\n",
    "        pred_labels = (pred > 0.5).float() \n",
    "        auc = roc_auc_score(y_train.cpu(), pred.cpu())\n",
    "\n",
    "    # 混淆矩阵计算\n",
    "        tn, fp, fn, tp = confusion_matrix(y_train.cpu(), pred_labels.cpu()).ravel()\n",
    "\n",
    "        # Specificity (SP)\n",
    "        sp = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        \n",
    "        acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "        # Sensitivity (SN)\n",
    "        sn = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        # Matthews Correlation Coefficient (MCC)\n",
    "        mcc = matthews_corrcoef(y_train.cpu(), pred_labels.cpu())\n",
    "    print(f\"ACC: {acc:.4f}, AUC: {auc:.4f}, SP: {sp:.4f}, MCC: {mcc:.4f}, SN: {sn:.4f}\")\n",
    "    return torch.mean((torch.round(model(X_train)[:, 0]) == y_train[:, 0]).float())\n",
    "\n",
    "def test_acc():\n",
    "    pred=model(X_test)\n",
    "    with torch.no_grad():\n",
    "        pred_labels = (pred > 0.5).float() \n",
    "        auc = roc_auc_score(y_test.cpu(), pred.cpu())\n",
    "\n",
    "    # 混淆矩阵计算\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test.cpu(), pred_labels.cpu()).ravel()\n",
    "\n",
    "        # Specificity (SP)\n",
    "        sp = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        \n",
    "        acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "        # Sensitivity (SN)\n",
    "        sn = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "        # Matthews Correlation Coefficient (MCC)\n",
    "        mcc = matthews_corrcoef(y_test.cpu(), pred_labels.cpu())\n",
    "    print(f\"ACC: {acc:.4f}, AUC(test): {auc:.4f}, SP: {sp:.4f}, MCC: {mcc:.4f}, SN: {sn:.4f}\")\n",
    "    return torch.mean((torch.round(model(X_test)[:, 0]) == y_test[:, 0]).float())\n",
    "\n",
    "# results = model.train(dataset, opt=\"LBFGS\", steps=10, metrics=(train_acc, test_acc)) ,lamb=0.001 lamb_entropy=4.,lamb=0.1,lamb_l1=2.5,\n",
    "# lamb=0.005 train/fit\n",
    "results = model.fit(dataset, opt=\"LBFGS\", steps=30, metrics=(train_acc, test_acc));\n",
    "# print(results['train_acc'][-1], results['test_acc'][-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T08:01:21.630081Z",
     "start_time": "2024-08-29T07:05:22.608677Z"
    }
   },
   "id": "3691ce475367ec80"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.90\n",
      "Training AUC: 0.96\n",
      "Test Accuracy: 0.83\n",
      "Test AUC: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangli/anaconda3/envs/transformer-env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "def calculate_GAAC(protein_list):\n",
    "    # 定义氨基酸分组\n",
    "    groups = {\n",
    "        'G1': 'GAVLMI',  # 脂肪族\n",
    "        'G2': 'FYW',     # 芳香族\n",
    "        'G3': 'KRH',     # 带正电\n",
    "        'G4': 'DE',      # 带负电\n",
    "        'G5': 'STCPNQ'   # 不带电\n",
    "    }\n",
    "\n",
    "    # 初始化结果列表\n",
    "    results = []\n",
    "\n",
    "    # 遍历蛋白质序列\n",
    "    for protein in protein_list:\n",
    "        # 计算每个组的频率\n",
    "        group_counts = {key: 0 for key in groups}\n",
    "        total_length = len(protein)\n",
    "        \n",
    "        for aa in protein:\n",
    "            for group_name, group_aa in groups.items():\n",
    "                if aa in group_aa:\n",
    "                    group_counts[group_name] += 1\n",
    "                    break\n",
    "        \n",
    "        # 计算频率\n",
    "        group_frequencies = {key: count / total_length for key, count in group_counts.items()}\n",
    "        results.append(group_frequencies)\n",
    "\n",
    "    return results\n",
    "\n",
    "# 示例蛋白质序列列表\n",
    "protein_list = [\"GAVLMIKRHDE\", \"STCPNQFYWG\", \"GAVLMIKRHDEGAVLMIKRHDE\"]\n",
    "gaac_features = calculate_GAAC(protein_list)\n",
    "\n",
    "for i, features in enumerate(gaac_features):\n",
    "    print(f\"Protein {i + 1}: {features}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-29T08:14:53.933628Z",
     "start_time": "2024-08-29T08:14:53.884634Z"
    }
   },
   "id": "b2ff815b947bb59d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
